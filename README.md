# RL_memory

A research project in vision-based deep reinforcement learning centered on transfer learning, unsupervised representation learning, and applying attention mechanisms to interpret memories.


References:
- Chen et al. (2020). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR. 
- Devlin et al. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. 
- Hessel et al. (2018). Rainbow: Combining improvements in deep reinforcement learning. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 32, No. 1).
- Mnih et al. (2015). Human-level control through deep reinforcement learning. Nature, 518(7540), 529-533. 
- Srinivas et al. (2020). CURL: Contrastive unsupervised representations for reinforcement learning. In International Conference on Machine Learning (pp. 5639-5650). PMLR. 
- Oh et al. (2016). Control of memory, active perception, and action in Minecraft. In International Conference on Machine Learning (pp. 2790-2799). PMLR. 
- Oord et al. (2018). Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748. 
- Zhu et al. (2020). Masked Contrastive Representation Learning for Reinforcement Learning. arXiv preprint arXiv:2010.07470.
